{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechrecognition in c:\\users\\rohith\\onedrive\\desktop\\speech to text - speech recognition\\venv310\\lib\\site-packages (3.14.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rohith\\onedrive\\desktop\\speech to text - speech recognition\\venv310\\lib\\site-packages (from speechrecognition) (4.13.1)\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning  libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE\n",
      "\n",
      "LibMambaUnsatisfiableError: Encountered problems while solving:\n",
      "  - package pyaudio-0.2.11-py27h0c8e037_1 requires python >=2.7,<2.8.0a0, but none of the providers can be installed\n",
      "\n",
      "Could not solve for environment specs\n",
      "The following packages are incompatible\n",
      "├─ pin-1 is installable and it requires\n",
      "│  └─ python 3.12.* , which can be installed;\n",
      "└─ pyaudio is not installable because there are no viable options\n",
      "   ├─ pyaudio 0.2.11 would require\n",
      "   │  └─ python >=2.7,<2.8.0a0 , which conflicts with any installable versions previously reported;\n",
      "   ├─ pyaudio 0.2.11 would require\n",
      "   │  └─ python >=3.10,<3.11.0a0 , which conflicts with any installable versions previously reported;\n",
      "   ├─ pyaudio 0.2.11 would require\n",
      "   │  └─ python >=3.11,<3.12.0a0 , which conflicts with any installable versions previously reported;\n",
      "   ├─ pyaudio 0.2.11 would require\n",
      "   │  └─ python >=3.5,<3.6.0a0 , which conflicts with any installable versions previously reported;\n",
      "   ├─ pyaudio 0.2.11 would require\n",
      "   │  └─ python >=3.6,<3.7.0a0 , which conflicts with any installable versions previously reported;\n",
      "   ├─ pyaudio 0.2.11 would require\n",
      "   │  └─ python >=3.7,<3.8.0a0 , which conflicts with any installable versions previously reported;\n",
      "   └─ pyaudio 0.2.11 would require\n",
      "      └─ python >=3.8,<3.9.0a0 , which conflicts with any installable versions previously reported.\n",
      "\n",
      "Pins seem to be involved in the conflict. Currently pinned specs:\n",
      " - python 3.12.* (labeled as 'pin-1')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install the module\n",
    "!pip install speechrecognition\n",
    "# !conda install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Speech to Text in Real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Input', 'Microphone (ED117)', 'Microphone (Realtek(R) Audio)', 'Microsoft Sound Mapper - Output', 'Headphones (ED117)', 'virus speakers (Realtek(R) Audi', 'Primary Sound Capture Driver', 'Microphone (ED117)', 'Microphone (Realtek(R) Audio)', 'Primary Sound Driver', 'Headphones (ED117)', 'virus speakers (Realtek(R) Audio)', 'virus speakers (Realtek(R) Audio)', 'Headphones (ED117)', 'Microphone (ED117)', 'Microphone (Realtek(R) Audio)', 'Headphones 1 (Realtek HD Audio 2nd output with HAP)', 'Headphones 2 (Realtek HD Audio 2nd output with HAP)', 'PC Speaker (Realtek HD Audio 2nd output with HAP)', 'Speakers 1 (Realtek HD Audio output with HAP)', 'Speakers 2 (Realtek HD Audio output with HAP)', 'PC Speaker (Realtek HD Audio output with HAP)', 'Mic in at front panel (black) (Mic in at front panel (black))', 'Stereo Mix (Realtek HD Audio Stereo input)', 'Microphone Array (Realtek HD Audio Mic input)', 'Headphones (ED117)', 'Microphone (ED117)']\n",
      "Adjusting for ambient noise...\n",
      "Speak now...\n",
      "Speaker: hello\n",
      "Adjusting for ambient noise...\n",
      "Speak now...\n",
      "Speaker: hi Google\n",
      "Adjusting for ambient noise...\n",
      "Speak now...\n",
      "Speaker: thank you\n",
      "Adjusting for ambient noise...\n",
      "Speak now...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeak now...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     text \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "File \u001b[1;32mc:\\Users\\ROHITH\\OneDrive\\Desktop\\Speech to Text - Speech Recognition\\venv310\\lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ROHITH\\OneDrive\\Desktop\\Speech to Text - Speech Recognition\\venv310\\lib\\site-packages\\speech_recognition\\__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    532\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\ROHITH\\OneDrive\\Desktop\\Speech to Text - Speech Recognition\\venv310\\lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ROHITH\\OneDrive\\Desktop\\Speech to Text - Speech Recognition\\venv310\\lib\\site-packages\\pyaudio.py:608\u001b[0m, in \u001b[0;36mStream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    606\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import speech_recognition as sr\n",
    "\n",
    "# r = sr.Recognizer()\n",
    "\n",
    "# mic_list = sr.Microphone.list_microphone_names()\n",
    "# print(mic_list)\n",
    "\n",
    "# while True:\n",
    "#     with sr.Microphone() as source:\n",
    "#         print(\"Adjusting for ambient noise...\")  \n",
    "#         r.adjust_for_ambient_noise(source, duration=1)\n",
    "        \n",
    "#         print(\"Speak now...\")\n",
    "#         try:\n",
    "#             audio = r.listen(source, timeout=5)\n",
    "#             text = r.recognize_google(audio)\n",
    "#             print(\"Speaker:\", text)\n",
    "#             if text.lower() == 'quit':\n",
    "#                 break\n",
    "#         except Exception as e:\n",
    "#             print('Error:', e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Audio to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to audio...\n",
      "Audio: to speech recognition\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(\"test.wav\") as source:\n",
    "    print(\"Reading from file...\")\n",
    "    audio = r.record(source)  # Or use r.listen(source) if needed\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        print(\"Recognized Text:\", text)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
